# app.py (stable stateful version)
import io
from decimal import Decimal, InvalidOperation
from typing import Optional
import pandas as pd
import streamlit as st

# -----------------------
# åŸºç¡€è®¾ç½®
# -----------------------
st.set_page_config(page_title="æ”¶æ¬¾å¯¹è´¦åŠ©æ‰‹ | Treasury Matcher", layout="wide")
st.title("æ”¶æ¬¾å¯¹è´¦åŠ©æ‰‹ Treasury Matcher")

# -----------------------
# å·¥å…·å‡½æ•°
# -----------------------
def _to_decimal_series(s: pd.Series) -> pd.Series:
    def to_dec(x):
        if pd.isna(x):
            return pd.NA
        try:
            return Decimal(str(x).replace(",", "").strip())
        except (InvalidOperation, AttributeError):
            return pd.NA
    return s.map(to_dec)

def match_treasury_query(
    df_query: pd.DataFrame,
    df_treasury: pd.DataFrame,
    name_col_q: str = "å®¢æˆ·å§“å",
    amount_col_q: str = "å®ä»˜é‡‘é¢",
    date_col_q: str = "ä¸‹å•æ—¶é—´",
    name_col_t: str = "å®¢æˆ·å§“å",
    amount_col_t: str = "æ”¶æ¬¾é‡‘é¢",
    date_col_t: Optional[str] = "æ”¶æ¬¾æ—¥æœŸ",
    amount_tol: float = 0.01,
    suffix_query: str = "query",
    suffix_treasury: str = "treasury",
) -> pd.DataFrame:

    q = df_query.copy()
    t = df_treasury.copy()

    q["_idx_q"] = q.index
    t["_idx_t"] = t.index
    q[name_col_q] = q[name_col_q].astype(str).str.strip()
    t[name_col_t] = t[name_col_t].astype(str).str.strip()
    q["_amt_q"] = _to_decimal_series(q[amount_col_q])
    t["_amt_t"] = _to_decimal_series(t[amount_col_t])

    if date_col_q in q.columns:
        q["_ordertime"] = pd.to_datetime(q[date_col_q], errors="coerce")
    else:
        q["_ordertime"] = pd.NaT

    cand = q.merge(
        t,
        left_on=name_col_q,
        right_on=name_col_t,
        how="inner",
        suffixes=(f"_{suffix_query}", f"_{suffix_treasury}")
    )
    tol_dec = Decimal(str(amount_tol))
    cand["_amt_diff"] = (cand["_amt_q"] - cand["_amt_t"]).abs()
    cand_valid = cand[cand["_amt_diff"] <= tol_dec].copy()

    cand_valid.sort_values(by=["_amt_diff", "_ordertime"], inplace=True)
    cand_q_first = cand_valid.drop_duplicates(subset=["_idx_q"], keep="first")
    matched = cand_q_first.drop_duplicates(subset=["_idx_t"], keep="first")

    matched_q_idx = set(matched["_idx_q"].tolist())
    matched_t_idx = set(matched["_idx_t"].tolist())

    q_unmatched = q[~q["_idx_q"].isin(matched_q_idx)].copy()
    t_unmatched = t[~t["_idx_t"].isin(matched_t_idx)].copy()

    q_cols_orig = df_query.columns.tolist()
    t_cols_orig = df_treasury.columns.tolist()

    matched["_source"] = "matched"
    matched["_amount_match_within_tol"] = True
    out_matched = matched.copy()

    for col in t_cols_orig:
        if col not in q_unmatched.columns:
            q_unmatched[col] = pd.NA
    for col in q_cols_orig:
        if col not in t_unmatched.columns:
            t_unmatched[col] = pd.NA

    def add_prefix_for_side(df, cols, prefix):
        rename_map = {c: f"{prefix}{c}" for c in cols if c in df.columns}
        return df.rename(columns=rename_map)

    out_matched = add_prefix_for_side(out_matched, q_cols_orig, f"{suffix_query}.")
    out_matched = add_prefix_for_side(out_matched, t_cols_orig, f"{suffix_treasury}.")

    q_unmatched_pref = add_prefix_for_side(q_unmatched[q_cols_orig], q_cols_orig, f"{suffix_query}.")
    for c in t_cols_orig:
        q_unmatched_pref[f"{suffix_treasury}.{c}"] = pd.NA
    q_unmatched_pref["_source"] = "query_only"
    q_unmatched_pref[f"{suffix_query}._idx_q"] = q_unmatched["_idx_q"]
    q_unmatched_pref[f"{suffix_treasury}._idx_t"] = pd.NA
    q_unmatched_pref["_amt_diff"] = pd.NA
    q_unmatched_pref["_amount_match_within_tol"] = False
    q_unmatched_pref["_ordertime"] = q["_ordertime"][q_unmatched["_idx_q"]].values

    t_unmatched_pref = add_prefix_for_side(t_unmatched[t_cols_orig], t_cols_orig, f"{suffix_treasury}.")
    for c in q_cols_orig:
        t_unmatched_pref[f"{suffix_query}.{c}"] = pd.NA
    t_unmatched_pref["_source"] = "treasury_only"
    t_unmatched_pref[f"{suffix_query}._idx_q"] = pd.NA
    t_unmatched_pref[f"{suffix_treasury}._idx_t"] = t_unmatched["_idx_t"]
    t_unmatched_pref["_amt_diff"] = pd.NA
    t_unmatched_pref["_amount_match_within_tol"] = False
    t_unmatched_pref["_ordertime"] = pd.NaT

    if "_ordertime" not in out_matched.columns and f"{suffix_query}.{date_col_q}" in out_matched.columns:
        out_matched["_ordertime"] = pd.to_datetime(
            out_matched[f"{suffix_query}.{date_col_q}"], errors="coerce"
        )
    elif "_ordertime" not in out_matched.columns:
        out_matched["_ordertime"] = pd.NaT

    out = pd.concat([out_matched, q_unmatched_pref, t_unmatched_pref], ignore_index=True)
    out.sort_values(by="_ordertime", inplace=True, kind="mergesort")
    out.reset_index(drop=True, inplace=True)

    q_name = f"{suffix_query}.{name_col_q}"
    q_amt  = f"{suffix_query}.{amount_col_q}"
    q_date = f"{suffix_query}.{date_col_q}"
    t_name = f"{suffix_treasury}.{name_col_t}"
    t_amt  = f"{suffix_treasury}.{amount_col_t}"
    t_date_full = f"{suffix_treasury}.{date_col_t}" if (date_col_t and f"{suffix_treasury}.{date_col_t}" in out.columns) else None

    final_cols = {
        "å®¢æˆ·å§“å_query": out[q_name] if q_name in out.columns else pd.NA,
        "å®ä»˜é‡‘é¢": out[q_amt] if q_amt in out.columns else pd.NA,
        "ä¸‹å•æ—¶é—´": out[q_date] if q_date in out.columns else pd.NaT,
        "å®¢æˆ·å§“å_treasury": out[t_name] if t_name in out.columns else pd.NA,
        "æ”¶æ¬¾é‡‘é¢": out[t_amt] if t_amt in out.columns else pd.NA,
        "åŒ¹é…ç»“æœ": out["_source"].eq("matched")
    }
    if t_date_full:
        final_cols["æ”¶æ¬¾æ—¥æœŸ"] = out[t_date_full]
    else:
        final_cols["æ”¶æ¬¾æ—¥æœŸ"] = pd.NaT

    final = pd.DataFrame(final_cols).sort_values(by="ä¸‹å•æ—¶é—´", kind="mergesort").reset_index(drop=True)

    mask_true_missing_name = final["åŒ¹é…ç»“æœ"] & final["å®¢æˆ·å§“å_treasury"].isna()
    final.loc[mask_true_missing_name, "å®¢æˆ·å§“å_treasury"] = final.loc[mask_true_missing_name, "å®¢æˆ·å§“å_query"]

    return final

# -----------------------
# ç¼“å­˜ï¼šæŠŠâ€œè§£æExcelå­—èŠ‚ -> DataFrameâ€ç¼“å­˜ä½
# ä¼ å…¥ bytesï¼Œè¿™æ ·æ¯æ¬¡é‡è·‘ä¸ç”¨é‡æ–°ä¸Šä¼ 
# -----------------------
@st.cache_data(show_spinner=False)
def read_excel_sheets(file_bytes: bytes):
    xls = pd.ExcelFile(io.BytesIO(file_bytes))
    return xls.sheet_names

@st.cache_data(show_spinner=False)
def read_excel_df(file_bytes: bytes, sheet_name: str):
    return pd.read_excel(io.BytesIO(file_bytes), sheet_name=sheet_name)

# -----------------------
# ä¾§è¾¹æ å‚æ•°
# -----------------------
with st.sidebar:
    st.header("å‚æ•°è®¾ç½® / Settings")
    amount_tol = st.number_input("é‡‘é¢å®¹å·®ï¼ˆå…ƒï¼‰Amount Tolerance", min_value=0.0, value=0.01, step=0.01)
    st.caption("è¯´æ˜ï¼šé»˜è®¤0.01ï¼ˆåˆ†çº§åˆ«ï¼‰ã€‚å¦‚å› æ‰‹ç»­è´¹/å››èˆäº”å…¥å¯¼è‡´å·®å¼‚ï¼Œå¯é€‚å½“æ”¾å¤§ã€‚")

# -----------------------
# ä¸Šä¼ åŒºï¼ˆå•æ–‡ä»¶ æˆ– ä¸¤æ–‡ä»¶ï¼‰
# -----------------------
tab1, tab2 = st.tabs(["ğŸ“„ å•æ–‡ä»¶ï¼ˆå«ä¸¤ä¸ªSheetï¼‰", "ğŸ—‚ï¸ åˆ†åˆ«ä¸Šä¼ ä¸¤ä¸ªæ–‡ä»¶"])

# ç»Ÿä¸€çš„ session é”®å
SS = st.session_state

# ====== Tab1ï¼šå•æ–‡ä»¶ï¼Œå…ˆé€‰æ‹©sheetï¼Œå†è¯»å– ======
with tab1:
    file_one = st.file_uploader("ä¸Šä¼ å•ä¸ªExcelï¼ˆåŒæ—¶åŒ…å« Query & Treasury ä¸¤ä¸ªå·¥ä½œè¡¨ï¼‰", type=["xlsx", "xls"], key="file_one_uploader")
    if file_one is not None:
        # æŠŠæ–‡ä»¶å†…å®¹æŒä¹…åŒ–ä¸º bytesï¼Œé¿å…ç»„ä»¶é‡è·‘åä¸¢å¤±
        SS["file_one_bytes"] = file_one.getvalue()
        # è§£æ sheet åˆ—è¡¨ï¼ˆç¼“å­˜ï¼‰
        sheet_names = read_excel_sheets(SS["file_one_bytes"])

        with st.form("form_read_single", clear_on_submit=False):
            c1, c2 = st.columns(2)
            with c1:
                sheet_q = st.selectbox("é€‰æ‹©ä¸šåŠ¡æ˜ç»†Sheetï¼ˆQueryï¼‰", options=sheet_names, key="sheet_q")
            with c2:
                sheet_t = st.selectbox("é€‰æ‹©è´¢åŠ¡æµæ°´Sheetï¼ˆTreasuryï¼‰", options=sheet_names, index=min(1, len(sheet_names)-1), key="sheet_t")

            submitted = st.form_submit_button("è¯»å–è¯¥Excel", type="primary")
            if submitted:
                SS["df_query"] = read_excel_df(SS["file_one_bytes"], SS["sheet_q"])
                SS["df_treasury"] = read_excel_df(SS["file_one_bytes"], SS["sheet_t"])
                st.success("è¯»å–å®Œæˆ / Loaded.")
                st.rerun()

# ====== Tab2ï¼šåˆ†åˆ«ä¸Šä¼ ä¸¤æ–‡ä»¶ï¼Œç›´æ¥è¯»å–åˆ°ä¼šè¯ ======
with tab2:
    file_q = st.file_uploader("ä¸Šä¼ ä¸šåŠ¡æ˜ç»†ï¼ˆQueryï¼‰Excel", type=["xlsx", "xls"], key="file_q_uploader")
    file_t = st.file_uploader("ä¸Šä¼ è´¢åŠ¡æµæ°´ï¼ˆTreasuryï¼‰Excel", type=["xlsx", "xls"], key="file_t_uploader")

    if file_q is not None:
        SS["file_q_bytes"] = file_q.getvalue()
        # é»˜è®¤è¯»å–ç¬¬ä¸€ä¸ªsheet
        SS["df_query"] = pd.read_excel(io.BytesIO(SS["file_q_bytes"]), sheet_name=0)
    if file_t is not None:
        SS["file_t_bytes"] = file_t.getvalue()
        SS["df_treasury"] = pd.read_excel(io.BytesIO(SS["file_t_bytes"]), sheet_name=0)
    if (file_q is not None) and (file_t is not None):
        st.success("ä¸¤ä¸ªæ–‡ä»¶è¯»å–å®Œæˆ / Both loaded.")

# -----------------------
# æ˜ å°„ä¸è¿è¡Œï¼ˆä½¿ç”¨è¡¨å•ï¼Œé¿å…åŠé€”äº¤äº’å¯¼è‡´çŠ¶æ€ä¸¢å¤±ï¼‰
# -----------------------
if ("df_query" in SS) and ("df_treasury" in SS):
    df_query = SS["df_query"]
    df_treasury = SS["df_treasury"]

    st.subheader("åˆ—åæ˜ å°„ / Column Mapping")
    with st.form("form_mapping", clear_on_submit=False):
        c1, c2 = st.columns(2)

        # ç”¨å›ºå®šé¡ºåºçš„ list(df.columns) ä½œä¸º optionsï¼Œé¿å…ä¹±åº
        q_cols = list(df_query.columns)
        t_cols = list(df_treasury.columns)

        with c1:
            st.markdown("**ä¸šåŠ¡æ˜ç»†ï¼ˆQueryï¼‰åˆ—é€‰æ‹©**")
            q_name = st.selectbox("å®¢æˆ·å§“åï¼ˆQueryï¼‰", options=q_cols, key="q_name")
            q_amt  = st.selectbox("å®ä»˜é‡‘é¢ï¼ˆQueryï¼‰", options=q_cols, key="q_amt")
            q_date = st.selectbox("ä¸‹å•æ—¶é—´ï¼ˆQueryï¼‰", options=q_cols, key="q_date")

        with c2:
            st.markdown("**è´¢åŠ¡æµæ°´ï¼ˆTreasuryï¼‰åˆ—é€‰æ‹©**")
            t_name = st.selectbox("å®¢æˆ·å§“åï¼ˆTreasuryï¼‰", options=t_cols, key="t_name")
            t_amt  = st.selectbox("æ”¶æ¬¾é‡‘é¢ï¼ˆTreasuryï¼‰", options=t_cols, key="t_amt")
            t_date_opts = ["<æ— /None>"] + t_cols
            t_date_sel = st.selectbox("æ”¶æ¬¾æ—¥æœŸï¼ˆå¯é€‰ï¼‰", options=t_date_opts, key="t_date_sel")

        run = st.form_submit_button("å¼€å§‹åŒ¹é… / Run Matching", type="primary")

    if run:
        t_date = None if SS.get("t_date_sel") in (None, "<æ— /None>") else SS["t_date_sel"]
        try:
            result = match_treasury_query(
                df_query=df_query,
                df_treasury=df_treasury,
                name_col_q=SS["q_name"],
                amount_col_q=SS["q_amt"],
                date_col_q=SS["q_date"],
                name_col_t=SS["t_name"],
                amount_col_t=SS["t_amt"],
                date_col_t=t_date,
                amount_tol=amount_tol
            )
            st.success(f"åŒ¹é…å®Œæˆï¼šå…± {len(result)} è¡Œã€‚")
            st.dataframe(result, use_container_width=True, hide_index=True)

            csv_bytes = result.to_csv(index=False).encode("utf-8-sig")
            st.download_button("â¬‡ï¸ ä¸‹è½½CSV", data=csv_bytes, file_name="treasury_matching_result.csv", mime="text/csv")

            xlsx_buffer = io.BytesIO()
            with pd.ExcelWriter(xlsx_buffer, engine="xlsxwriter") as writer:
                result.to_excel(writer, index=False, sheet_name="result")
            st.download_button("â¬‡ï¸ ä¸‹è½½Excelï¼ˆXLSXï¼‰", data=xlsx_buffer.getvalue(),
                               file_name="treasury_matching_result.xlsx",
                               mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")
        except Exception as e:
            st.error(f"åŒ¹é…å¤±è´¥ï¼š{e}")
else:
    st.info("è¯·å…ˆä¸Šä¼ æ•°æ®æ–‡ä»¶ / Please upload your files.")
